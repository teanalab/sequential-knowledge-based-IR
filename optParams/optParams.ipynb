{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function \n",
    "from bs4 import BeautifulSoup\n",
    "from BeautifulSoup import SoupStrainer as sopstrain\n",
    "import subprocess\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import string\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cfg infile Name = /home/fj9124/projects/ir/seq_kb_ir/configs/trec7n8/queryTrec7n8\n",
      "cfg outfile Name = /home/fj9124/projects/ir/seq_kb_ir/configs/trec7n8/assoc/cnet/indriRunQuery.cfg\n",
      "collection index Dir = /scratch/index/indri_5_7/trec7n8\n",
      "knowledgGraph index Dir = /scratch/index/indri_5_7/trec7n8\n",
      "methodGraphsFileName = ['/home/fj9124/projects/ir/seq_kb_ir/graphs/assoc/cnet/graph.txt']\n",
      "col Qrels File Name = /home/fj9124/projects/ir/seq_kb_ir/qrels/trec7n8/qrels.csv\n",
      "runsFileName = /home/fj9124/projects/ir/seq_kb_ir/runs/assoc/trec7n8/cnet/indriRunQuery.runs\n",
      "evalsFileName = /home/fj9124/projects/ir/seq_kb_ir/evals/assoc/trec7n8/cnet/indriRunQuery.evals\n"
     ]
    }
   ],
   "source": [
    "knowledgGraph = \"cnet\" # conceptnet5AssocMod, gov, conceptnet5AssocMi, conceptnet5AssocHdl\n",
    "#knowledgGraph_ = ''.join([k.capitalize() if i>0 else k for i, k in enumerate(knowledgGraph)])\n",
    "collection = \"trec7n8\"\n",
    "method = \"assoc\" # hal, mi, assoc, assocMi, assocHal\n",
    "projectDir = \"/home/fj9124/projects/ir/seq_kb_ir/\" \n",
    "indexDir = \"/scratch/index/indri_5_7/\"\n",
    "colMethodConfigsDir = os.path.join(projectDir, \"configs\", collection, method)\n",
    "cfgInFileName = os.path.join(projectDir, \"configs\", collection, \"query\" + collection.capitalize()) \n",
    "print(\"cfg infile Name =\", cfgInFileName)\n",
    "cfgOutFileName=os.path.join(colMethodConfigsDir, knowledgGraph, \"indriRunQuery.cfg\") \n",
    "print(\"cfg outfile Name =\", cfgOutFileName)\n",
    "colIndexDir = os.path.join(indexDir, collection) \n",
    "print(\"collection index Dir =\", colIndexDir)\n",
    "if knowledgGraph in {\"cnet\"}:\n",
    "    knowledgGraphIndexDir = os.path.join(indexDir, collection)   \n",
    "else:\n",
    "    knowledgGraphIndexDir = os.path.join(indexDir, knowledgGraph)   \n",
    "print(\"knowledgGraph index Dir =\", knowledgGraphIndexDir)\n",
    "graphsDir = os.path.join(projectDir, \"graphs\")\n",
    "#methodGraphsDir = os.path.join(graphsDir, method)\n",
    "if method == \"hal\":\n",
    "    methodGraphsFileName = [os.path.join(graphsDir, method, knowledgGraph + \".txt\")]\n",
    "    print(\"methodGraphsFileName =\", methodGraphsFileName)\n",
    "elif method in {\"mi\", \"assoc\"}:\n",
    "    methodGraphsFileName = [os.path.join(graphsDir, method, knowledgGraph, \"graph.txt\")]\n",
    "    print(\"methodGraphsFileName =\", methodGraphsFileName)\n",
    "elif method in {\"assocMi\"}:\n",
    "    if knowledgGraph == \"conceptnet5AssocGov\":\n",
    "        methodGraphsFileName = [os.path.join(graphsDir, \"assoc\", collection, \"conceptnet5AssocMod\" + \".txt\")]\n",
    "        methodGraphsFileName += [os.path.join(graphsDir, \"mi\", collection, \"gov\" + \".txt\")]\n",
    "        print(\"methodGraphsFileName =\", methodGraphsFileName)\n",
    "elif method in {\"assocHal\"}:\n",
    "    if knowledgGraph == \"conceptnet5AssocGov\":\n",
    "        methodGraphsFileName = [os.path.join(graphsDir, \"assoc\", collection, \"conceptnet5AssocMod\" + \".txt\")]\n",
    "        methodGraphsFileName += [os.path.join(graphsDir, \"hal\", \"gov\" + \".txt\")]\n",
    "        print(\"methodGraphsFileName =\", methodGraphsFileName)\n",
    "qrelsDir = os.path.join(projectDir, \"qrels\")\n",
    "colQrelsDir = os.path.join(qrelsDir, collection)\n",
    "colQrelsFileName = os.path.join(colQrelsDir, \"qrels.csv\")\n",
    "print(\"col Qrels File Name =\", colQrelsFileName)\n",
    "runsFileName = os.path.join(projectDir, \"runs\", method, collection, knowledgGraph, \"indriRunQuery.runs\") \n",
    "print(\"runsFileName =\", runsFileName)\n",
    "evalsFileName = os.path.join(projectDir, \"evals\", method, collection, knowledgGraph, \"indriRunQuery.evals\") \n",
    "print(\"evalsFileName =\", evalsFileName)\n",
    "#expansionCount = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing: ['go', 'read']\n"
     ]
    }
   ],
   "source": [
    "def splitStemText(text):\n",
    "    text = re.sub('/|-|\\\"|_',' ', text) # replace - and slash with space\n",
    "    words = text.split()\n",
    "    stemmedWords = []\n",
    "    for w in words:\n",
    "        w = re.sub('\\(|\\)|\\'s|,','', w) # remove paranthesis, apostrophe s, comma\n",
    "        w = re.sub('\\'','', w) # remove apostrophe\n",
    "        cmd = \"dumpindex \" + knowledgGraphIndexDir + \" t \" + w + \" | head -n1\"\n",
    "        #print(\"cmd =\", cmd)\n",
    "        stemmedWords.append(subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE).stdout.read().split()[1])\n",
    "    return (stemmedWords)\n",
    "\n",
    "print (\"testing:\", splitStemText(\"going reading\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/fj9124/projects/ir/seq_kb_ir/graphs/assoc/cnet/graph.txt\n",
      "reading graphs...\n",
      "size of rWords = 212531\n"
     ]
    }
   ],
   "source": [
    "rWords1 = dict()\n",
    "rWords = dict()\n",
    "if method != \"dir\":\n",
    "    print(methodGraphsFileName[0])\n",
    "    print(\"reading graphs...\")\n",
    "    with open(methodGraphsFileName[0], 'r') as graphFile:\n",
    "        oWord = \"\"\n",
    "        for i, row in enumerate(graphFile):\n",
    "            columns = row.split('\\t')\n",
    "            if(len(columns)==1):\n",
    "                oWord = columns[0].strip()\n",
    "            else:\n",
    "                rWord = columns[0].strip()\n",
    "                meas = np.float(columns[1].strip())\n",
    "                if oWord in rWords:\n",
    "                    rWords[oWord] += [{rWord:meas}]\n",
    "#                        rWords1[oWord][rWord] = meas\n",
    "                else:\n",
    "                    rWords[oWord] = [{rWord:meas}]\n",
    "                    #rWords1[oWord] = {rWord:meas}\n",
    "print(\"size of rWords =\", len(rWords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if(len(methodGraphsFileName)>1):\n",
    "    print(methodGraphsFileName[1])\n",
    "    \n",
    "    if method != \"dir\":\n",
    "        print(\"reading graphs...\")\n",
    "        with open(methodGraphsFileName[1], 'r') as graphFile:\n",
    "            oWord = \"\"\n",
    "            for i, row in enumerate(graphFile):\n",
    "                columns = row.split('\\t')\n",
    "                if(len(columns)==1):\n",
    "                    oWord = columns[0].strip()\n",
    "                else:\n",
    "                    rWord = columns[0].strip()\n",
    "                    meas = np.float(columns[1].strip())\n",
    "                    if oWord in rWords1:\n",
    "#                        rWords1[oWord] += [{rWord:meas}]\n",
    "                        rWords1[oWord][rWord] = meas\n",
    "                    else:\n",
    "#                        rWords1[oWord] = [{rWord:meas}]\n",
    "                        rWords1[oWord] = {rWord:meas}\n",
    "    print(\"size of rWords1 =\", len(rWords1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#rWords1 = dict()\n",
    "#import operator\n",
    "#print(rWords1[\"consum\"])\n",
    "#print(sorted(rWords1[\"consum\"], key=operator.itemgetter(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-->  {'pawn': 1.0}\n",
      "-->  {'pawn': 1.0}\n",
      "-->  {'rook': 1.0}\n",
      "-->  {'rook': 1.0}\n",
      "on reason person book ticket\n",
      "-->  {'go on vacat': 1.0}\n",
      "encount with friend\n",
      "-->  {'plai basketbal': 1.0}\n",
      "bean-stalk\n",
      "-->  {'bean': 1.0}\n",
      "antitrad wind\n",
      "-->  {'antitrad': 1.0}\n",
      "-->  {'prevail wind': 1.58496250072}\n",
      "canada goos\n",
      "-->  {'canada': 1.0}\n",
      "-->  {'larg north american bird that honk': 1.58496250072}\n",
      "spiderl\n",
      "-->  {'-ling': 1.0}\n",
      "vinalon\n",
      "-->  {'vinyl': 1.0}\n",
      "utnapishtim\n",
      "-->  {'semit deiti': 1.58496250072}\n",
      "spideri\n",
      "-->  {'spider': 1.0}\n",
      "calvin-benson cycl\n",
      "-->  {'calvin cycl': 1.0}\n",
      "salt flat\n",
      "-->  {'flat': 1.58496250072}\n",
      "steller sea-lion\n",
      "-->  {'eumetopia jubatu': 1.0}\n",
      "fuck your mom in ass\n",
      "-->  {'regard as taboo': 1.0}\n",
      "nunneri\n",
      "-->  {'brothel': 1.0}\n",
      "-->  {'convent': 1.58496250072}\n",
      "-->  {'nun': 1.0}\n",
      "ecolog servic\n",
      "-->  {'servic': 1.0}\n",
      "reel in\n",
      "-->  {'reel': 1.0}\n",
      "w:polish corridor\n",
      "-->  {'corridor': 1.0}\n",
      "cardiospermum\n",
      "-->  {'dicot genu': 1.58496250072}\n",
      "-->  {'sapindacea': 1.58496250072}\n",
      "modelessli\n",
      "-->  {'model': 1.0}\n",
      "houyhnhnm\n",
      "-->  {'fiction charact': 1.58496250072}\n",
      "-->  {'imaginari place': 1.58496250072}\n",
      "seven-year itch\n",
      "-->  {'seven': 1.0}\n"
     ]
    }
   ],
   "source": [
    "for j, (ow, rws) in  enumerate(rWords.iteritems()):\n",
    "    print (ow)\n",
    "    for i, rw in enumerate(rws):\n",
    "        print (\"--> \", rw)\n",
    "        if i>10:\n",
    "            break\n",
    "    if j>20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    qRWords = qRWords | rWords_s\\nqRWords_d = dict()\\nfor w in qRWords:\\n    rWords1[w][]\\n    if w in qRWords_d:\\n        qRWords_d[w] += rWords1[w]\\n    else:\\n        qRWords_d[w] = \\nprint(qRWords)\\n'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keys of rWords are important\n",
    "# values of rWords1 are important\n",
    "regex = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "def getRelWords(rWords, rWords1, origWords, expansionCount):\n",
    "#origWords = [\"consum\", \"laura\"]\n",
    "    #text_string = \"\"\n",
    "    qRWords01 = dict()\n",
    "    for ow in origWords:\n",
    "        #print(ow, rWords[ow])\n",
    "        #print(ow)\n",
    "        qRWords = set()\n",
    "        #print(\"rWords =\", rWords[ow])\n",
    "        #rWords_ow = dict((i.keys()[0], sum(d.get(i.keys()[0], 0) for d in rWords[ow])) for i in rWords[ow])\n",
    "        rWords_ow = dict((i.keys()[0], sum(d.get(i.keys()[0], 0) for d in rWords.get(ow, dict()))) for i in rWords.get(ow, dict()))\n",
    "        #break\n",
    "        if ow in rWords:\n",
    "            qRWords = set([i.keys()[0] for i in rWords[ow]])\n",
    "        \n",
    "        #qRWords1 = rWords1[ow]\n",
    "        #print(\"ow, qRWords =  \", ow, qRWords)\n",
    "\n",
    "        #print(\"----------------\\n\")\n",
    "        qRWords1 = rWords1.get(ow, dict())\n",
    "        #print(\"ow, qRWords1 =  \", ow, qRWords1)\n",
    "        #for qrw in qRWords:\n",
    "        cnetCoeff = 0.2;\n",
    "        for qrw, meas in rWords_ow.iteritems():\n",
    "            if qrw in qRWords01:\n",
    "                qRWords01[qrw] += (1-cnetCoeff) * qRWords1.get(qrw, 0) + cnetCoeff * meas\n",
    "            else:\n",
    "                #if qRWords1.get(qrw, 0) > 0:\n",
    "                qRWords01[qrw] = (1-cnetCoeff) * qRWords1.get(qrw, 0) + cnetCoeff * meas\n",
    "    sorted_qRWords01 = sorted(qRWords01.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    #print(\"sorted_qRWords01 =\",sorted_qRWords01)\n",
    "    text_string = \"\"\n",
    "    for rw, v in sorted_qRWords01[0: expansionCount]:\n",
    "        #print (\"rw =\", rw)\n",
    "        if  all(c in string.printable for c in rw):\n",
    "            rw = regex.sub(' ', rw)\n",
    "            #rw = \"\".join([ c for c in rw if c.isalpha() or c == \" \" ])\n",
    "            text_string += rw + \" \"\n",
    "    #text_string = ' '.join([i[0] for i in sorted_qRWords01[0: expansionCount]])\n",
    "#    text_string = ' '.join(sorted_qRWords01.keys()[0: expansionCount])\n",
    "    return(text_string)\n",
    "\"\"\"\n",
    "    qRWords = qRWords | rWords_s\n",
    "qRWords_d = dict()\n",
    "for w in qRWords:\n",
    "    rWords1[w][]\n",
    "    if w in qRWords_d:\n",
    "        qRWords_d[w] += rWords1[w]\n",
    "    else:\n",
    "        qRWords_d[w] = \n",
    "print(qRWords)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "regex = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "def genQueries(intCoeff, expansionCount, dirCoeff):\n",
    "    #    #print(\"intCoeff =\", intCoeff)\n",
    "    with open(cfgInFileName, 'r') as inFile:\n",
    "        reader = inFile.read()\n",
    "        soup = BeautifulSoup(reader, 'lxml')\n",
    "        soupNew = BeautifulSoup(\"\", 'lxml')\n",
    "        parameters_tag = soupNew.new_tag(\"parameters\")\n",
    "        index_tag = soupNew.new_tag(\"index\")\n",
    "        index_tag.string = colIndexDir\n",
    "        parameters_tag.append(index_tag)\n",
    "        if collection in {\"aquaint\", \"gov\"}:\n",
    "            tags = soup.find_all(['doc'])\n",
    "        elif collection in {\"robust\", \"trec7n8\"}:\n",
    "            tags = soup.find_all(['top'])\n",
    "            #print(tags)\n",
    "\n",
    "        for tag in tags:\n",
    "            #print(\"tag =\", tag)\n",
    "            #print('docno =', tag.find('docno').string)\n",
    "            #print('text =', tag.find('text').string.strip())\n",
    "            doc_tag = soupNew.new_tag(\"query\")\n",
    "\n",
    "            docno_tag = soupNew.new_tag(\"number\")\n",
    "            if collection in {\"aquaint\", \"gov\"}:\n",
    "                docno_tag.string = (tag.find('docno').string).strip()\n",
    "            elif collection in {\"robust\", \"trec7n8\"}:\n",
    "                result = re.search('<num> Number: (.*)\\n', str(tag))                \n",
    "                docno_tag.string = result.group(1).strip()\n",
    "            doc_tag.append(docno_tag)\n",
    "\n",
    "            text_tag = soupNew.new_tag(\"text\")\n",
    "            text_tag.string = \"#weight(\" \n",
    "\n",
    "            if collection in {\"aquaint\", \"gov\"}:\n",
    "                origWords = splitStemText(tag.find('text').string.strip())\n",
    "            elif collection in {\"robust\", \"trec7n8\"}:\n",
    "                result = re.search('<title>(.*)\\n', str(tag))                \n",
    "                origWords = splitStemText(result.group(1).strip())\n",
    "            #print(\"origWords =\", origWords)\n",
    "                    \n",
    "            text_tag.string += str(1-intCoeff) + \" #combine(\" \n",
    "            for ow in set(origWords):\n",
    "                ow = regex.sub(' ', ow)\n",
    "                text_tag.string += ow + \" \"\n",
    "            text_tag.string += \") \"\n",
    "\n",
    "            text_string = \"\"\n",
    "            #if len(rWords1) > 0:\n",
    "            \"\"\"\n",
    "            text_string = getRelWords(rWords, rWords1, origWords, expansionCount)\n",
    "           \n",
    "            else:\n",
    "            \n",
    "            for ow in origWords:\n",
    "                relWords = rWords.get(ow, [])[0: expansionCount]\n",
    "                #relWords = getRelatedWords(ow) \n",
    "                #print(\"relWords =\", relWords)\n",
    "                for rw in {i.keys()[0] for i in relWords}:\n",
    "                    if  all(c in string.printable for c in rw):\n",
    "                        rw = regex.sub(' ', rw)\n",
    "                        #rw = \"\".join([ c for c in rw if c.isalpha() or c == \" \" ])\n",
    "                        text_string += rw + \" \"\n",
    "            \"\"\"\n",
    "            for ow in origWords:\n",
    "                #relWords1 = rWords1.get(ow, [])[0: expansionCount]\n",
    "                #qrWords_ow = dict((i.keys()[0], sum(d.get(i.keys()[0], 0) for d in rWords[ow])) for i in rWords[ow])\n",
    "                #qrWords_ow = dict((i.keys()[0], sum(d.get(i.keys()[0], 0) for d in rWords.get(ow, dict()))) for i in rWords.get(ow, dict()))\n",
    "                relWords = rWords.get(ow, [])\n",
    "                #print(\"relWords1 =\", relWords1)\n",
    "                #relWords = getRelatedWords(ow) \n",
    "                #print(\"relWords =\", relWords)\n",
    "                #qRWords = rWords.get(ow, dict())\n",
    "                #print(\"qRWords =\", qRWords)\n",
    "                counter = 0\n",
    "                #print(\"relWords =\", relWords)\n",
    "                #for rw in {i for i in relWords}:\n",
    "                for rw in {i.keys()[0] for i in relWords}:\n",
    "                    #print(\"--->\", rw)\n",
    "                    #if rw not in qrWords_ow.keys():\n",
    "                    #    continue\n",
    "                    if (counter>expansionCount):\n",
    "                        break\n",
    "                    if  all(c in string.printable for c in rw):\n",
    "                        rw = regex.sub(' ', rw)\n",
    "                        #rw = \"\".join([ c for c in rw if c.isalpha() or c == \" \" ])\n",
    "                        text_string += rw + \" \"\n",
    "                    counter += 1\n",
    "                    \n",
    "            #print(\"text_string =\", text_string)\n",
    "            if len(text_string)>3:\n",
    "                text_tag.string += str(intCoeff) + \" #combine(\" \n",
    "                #print(\"text_string =\", text_string)\n",
    "                text_tag.string += text_string.encode('utf-8')\n",
    "                text_tag.string += \") \"\n",
    "\n",
    "            text_tag.string += \") \"\n",
    "\n",
    "            doc_tag.append(text_tag)\n",
    "\n",
    "            parameters_tag.append(doc_tag)\n",
    "            #print(doc_tag)\n",
    "\n",
    "        rule_tag = soupNew.new_tag(\"rule\")\n",
    "        rule_tag.string = \"method:dir,mu:\" + str(dirCoeff)\n",
    "        #rule_tag.string = \"method:two\"\n",
    "        parameters_tag.append(rule_tag)\n",
    "\n",
    "        #intCoeff_tag = soupNew.new_tag(\"intCoeff\")\n",
    "        #intCoeff_tag.string = \"0.8\"\n",
    "        #parameters_tag.append(intCoeff_tag)\n",
    "\n",
    "        threads_tag = soupNew.new_tag(\"threads\")\n",
    "        threads_tag.string = \"32\"\n",
    "        parameters_tag.append(threads_tag)\n",
    "\n",
    "        count_tag = soupNew.new_tag(\"count\")\n",
    "        count_tag.string = \"1000\"\n",
    "        parameters_tag.append(count_tag)\n",
    "\n",
    "        trecFormat_tag = soupNew.new_tag(\"trecFormat\")\n",
    "        trecFormat_tag.string = \"true\"\n",
    "        parameters_tag.append(trecFormat_tag)\n",
    "\n",
    "        soupNew.append(parameters_tag)\n",
    "        #print(soupNew.prettify())\n",
    "    #print(\"outFileName =\", outFileName)\n",
    "    with open( cfgOutFileName, 'w') as outFile:\n",
    "        soupNewStr = str(soupNew)\n",
    "        soupNewStr = soupNewStr.replace(\"query>\", \"query>\\n\").replace(\"<text>\", \"\\n<text>\\n\").replace(\"</text>\", \"\\n</text>\\n\").replace(\"</index>\", \"</index>\\n\").replace(\"\\n<index>\", \"<index>\")\n",
    "        outFile.write(soupNewStr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def precisionCompute(intCoeffs, expansionCounts, dirCoeffs):\n",
    "    mapPrecs = dict()\n",
    "    for intCoeff in intCoeffs:\n",
    "        for expansionCount in expansionCounts:\n",
    "            for dirCoeff in dirCoeffs:\n",
    "                genQueries(intCoeff, expansionCount, dirCoeff)\n",
    "                subprocess.Popen(\"IndriRunQuery \" + cfgOutFileName + \" > \" + runsFileName, shell=True, stdout=subprocess.PIPE).stdout.read()\n",
    "                cmd = \"trec_eval -q \" + colQrelsFileName + \" \" + runsFileName + \" > \" + evalsFileName\n",
    "                subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE).stdout.read()\n",
    "                cmd = \"cat \" + evalsFileName + \" | grep map | grep all | grep -v gm | awk '{print $3}' \"\n",
    "                #print (\"cmd = \", cmd)\n",
    "                mapPrec = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE).stdout.read()\n",
    "                print(\"intCoeff, expansionCount, dirCoeff, map precision =\", intCoeff, expansionCount, dirCoeff, mapPrec)\n",
    "                mapPrecs[intCoeff] = mapPrec\n",
    "    return mapPrecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#intCoeffs = [0, 0.001, 0.01, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1]\n",
    "#intCoeffs = [ 0.6 ]\n",
    "#intCoeffs = [0.5]\n",
    "#intCoeffs = np.arange(0.1, 0.9, 0.1)\n",
    "intCoeffs = [ 0.3 ]\n",
    "expansionCounts = [ 85 ]\n",
    "dirCoeffs = [ 600 ]\n",
    "dirCoeffs = range(200, 4000, 200)\n",
    "mapPrecs = precisionCompute(intCoeffs, expansionCounts, dirCoeffs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
