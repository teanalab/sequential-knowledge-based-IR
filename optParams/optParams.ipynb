{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function \n",
    "from bs4 import BeautifulSoup\n",
    "from BeautifulSoup import SoupStrainer as sopstrain\n",
    "import subprocess\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import string\n",
    "import operator\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cfg infile Name = /home/fj9124/projects/ir/seq_kb_ir/configs/trec7n8/queryTrec7n8\n",
      "cfg outfile Name = /home/fj9124/projects/ir/seq_kb_ir/configs/trec7n8/assoc2/cnet/indriRunQuery.cfg\n",
      "collection index Dir = /scratch/index/indri_5_7/trec7n8\n",
      "knowledgGraph index Dir = /scratch/index/indri_5_7/trec7n8\n",
      "methodGraphsFileName = ['/home/fj9124/projects/ir/seq_kb_ir/graphs/assoc/cnet/graph.txt']\n",
      "col Qrels File Name = /home/fj9124/projects/ir/seq_kb_ir/qrels/trec7n8/qrels.csv\n",
      "runsFileName = /home/fj9124/projects/ir/seq_kb_ir/runs/assoc2/trec7n8/cnet/indriRunQuery.runs\n",
      "evalsFileName = /home/fj9124/projects/ir/seq_kb_ir/evals/assoc2/trec7n8/cnet/indriRunQuery.evals\n",
      "countsResultsFile = /home/fj9124/projects/ir/seq_kb_ir/occuranceCount/results/trec7n8.txt\n"
     ]
    }
   ],
   "source": [
    "knowledgGraph = \"cnet\" # conceptnet5AssocMod, gov, conceptnet5AssocMi, conceptnet5AssocHdl\n",
    "#knowledgGraph_ = ''.join([k.capitalize() if i>0 else k for i, k in enumerate(knowledgGraph)])\n",
    "collection = \"trec7n8\"\n",
    "method = \"assoc2\" # hal, mi, assoc, assocMi, assocHal\n",
    "simMeasure = \"mi\" # mi, cnet\n",
    "projectDir = \"/home/fj9124/projects/ir/seq_kb_ir/\" \n",
    "indexDir = \"/scratch/index/indri_5_7/\"\n",
    "colMethodConfigsDir = os.path.join(projectDir, \"configs\", collection, method)\n",
    "cfgInFileName = os.path.join(projectDir, \"configs\", collection, \"query\" + collection.capitalize()) \n",
    "print(\"cfg infile Name =\", cfgInFileName)\n",
    "cfgOutFileName=os.path.join(colMethodConfigsDir, knowledgGraph, \"indriRunQuery.cfg\") \n",
    "print(\"cfg outfile Name =\", cfgOutFileName)\n",
    "colIndexDir = os.path.join(indexDir, collection) \n",
    "print(\"collection index Dir =\", colIndexDir)\n",
    "if knowledgGraph in {\"cnet\"}:\n",
    "    knowledgGraphIndexDir = os.path.join(indexDir, collection)   \n",
    "else:\n",
    "    knowledgGraphIndexDir = os.path.join(indexDir, knowledgGraph)   \n",
    "print(\"knowledgGraph index Dir =\", knowledgGraphIndexDir)\n",
    "graphsDir = os.path.join(projectDir, \"graphs\")\n",
    "#methodGraphsDir = os.path.join(graphsDir, method)\n",
    "if method == \"hal\":\n",
    "    methodGraphsFileName = [os.path.join(graphsDir, method, knowledgGraph + \".txt\")]\n",
    "    print(\"methodGraphsFileName =\", methodGraphsFileName)\n",
    "elif method.translate(None, string.digits) in {\"mi\", \"assoc\"}:\n",
    "    methodGraphsFileName = [os.path.join(graphsDir, method.translate(None, string.digits), knowledgGraph, \"graph.txt\")]\n",
    "    print(\"methodGraphsFileName =\", methodGraphsFileName)\n",
    "elif method in {\"assocMi\"}:\n",
    "    if knowledgGraph == \"conceptnet5AssocGov\":\n",
    "        methodGraphsFileName = [os.path.join(graphsDir, \"assoc\", collection, \"conceptnet5AssocMod\" + \".txt\")]\n",
    "        methodGraphsFileName += [os.path.join(graphsDir, \"mi\", collection, \"gov\" + \".txt\")]\n",
    "        print(\"methodGraphsFileName =\", methodGraphsFileName)\n",
    "elif method in {\"assocHal\"}:\n",
    "    if knowledgGraph == \"conceptnet5AssocGov\":\n",
    "        methodGraphsFileName = [os.path.join(graphsDir, \"assoc\", collection, \"conceptnet5AssocMod\" + \".txt\")]\n",
    "        methodGraphsFileName += [os.path.join(graphsDir, \"hal\", \"gov\" + \".txt\")]\n",
    "        print(\"methodGraphsFileName =\", methodGraphsFileName)\n",
    "qrelsDir = os.path.join(projectDir, \"qrels\")\n",
    "colQrelsDir = os.path.join(qrelsDir, collection)\n",
    "colQrelsFileName = os.path.join(colQrelsDir, \"qrels.csv\")\n",
    "print(\"col Qrels File Name =\", colQrelsFileName)\n",
    "runsFileName = os.path.join(projectDir, \"runs\", method, collection, knowledgGraph, \"indriRunQuery.runs\") \n",
    "print(\"runsFileName =\", runsFileName)\n",
    "evalsFileName = os.path.join(projectDir, \"evals\", method, collection, knowledgGraph, \"indriRunQuery.evals\") \n",
    "print(\"evalsFileName =\", evalsFileName)\n",
    "countsResultsFile = os.path.join(projectDir,\"occuranceCount\",\"results\",collection+\".txt\")\n",
    "print(\"countsResultsFile =\", countsResultsFile)\n",
    "#expansionCount = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of count_history = 81446\n",
      "#uw(#4( storm ) #4( be appear in sky )) \t 0\n",
      "#uw(#4( work on sundai )) \t 137\n",
      "#uw(#4( calm time )) \t 23\n",
      "#uw(#4( kill ) #4( prai )) \t 394\n",
      "#uw(#4( bank ) #4( teller offic )) \t 5\n",
      "#uw(#4( water ) #4( hydrogen )) \t 347\n",
      "#uw(#4( drug ) #4( take )) \t 8847\n",
      "#uw(#4( space ) #4( mostli empti )) \t 3\n",
      "#uw(#4( chang ) #4( edg )) \t 3803\n",
      "#uw(#4( happin )) \t 0\n",
      "#uw(#4( trade ) #4( countri )) \t 45838\n",
      "#uw(#4( game ) #4( leisur activ )) \t 23\n",
      "#uw(#4( round in shape )) \t 4\n",
      "#uw(#4( good ) #4( other person )) \t 411\n",
      "#uw(#4( smoke ) #4( fire )) \t 1842\n",
      "#uw(#4( spice up salad )) \t 1\n",
      "#uw(#4( be wound )) \t 410\n",
      "#uw(#4( good ) #4( hear nice new )) \t 0\n",
      "#uw(#4( teacher ) #4( teach student of class )) \t 0\n",
      "#uw(#4( deliveri )) \t 11268\n",
      "#uw(#4( bank ) #4( teller monei )) \t 23\n",
      "#uw(#4( swap share )) \t 106\n"
     ]
    }
   ],
   "source": [
    "count_history = dict()\n",
    "with open(countsResultsFile, 'r') as f:\n",
    "    reader = csv.reader(f, delimiter = \"\\t\")\n",
    "    count_history = {k:int(float(v)) for k,v in list(reader)}\n",
    "print(\"size of count_history =\", len(count_history))\n",
    "for i, (k, v) in enumerate(count_history.iteritems()):\n",
    "    print (k, '\\t', v)\n",
    "    if (i>20):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing: ['go', 'read']\n"
     ]
    }
   ],
   "source": [
    "def splitStemText(text):\n",
    "    text = re.sub('/|-|\\\"|_',' ', text) # replace - and slash with space\n",
    "    words = text.split()\n",
    "    stemmedWords = []\n",
    "    for w in words:\n",
    "        w = re.sub('\\(|\\)|\\'s|,','', w) # remove paranthesis, apostrophe s, comma\n",
    "        w = re.sub('\\'','', w) # remove apostrophe\n",
    "        cmd = \"dumpindex \" + knowledgGraphIndexDir + \" t \" + w + \" | head -n1\"\n",
    "        #print(\"cmd =\", cmd)\n",
    "        stemmedWords.append(subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE).stdout.read().split()[1])\n",
    "    return (stemmedWords)\n",
    "\n",
    "print (\"testing:\", splitStemText(\"going reading\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/fj9124/projects/ir/seq_kb_ir/graphs/assoc/cnet/graph.txt\n",
      "reading graphs...\n",
      "size of rWords = 212531\n"
     ]
    }
   ],
   "source": [
    "rWords1 = dict()\n",
    "rWords = dict()\n",
    "if method != \"dir\":\n",
    "    print(methodGraphsFileName[0])\n",
    "    print(\"reading graphs...\")\n",
    "    with open(methodGraphsFileName[0], 'r') as graphFile:\n",
    "        oWord = \"\"\n",
    "        for i, row in enumerate(graphFile):\n",
    "            columns = row.split('\\t')\n",
    "            if(len(columns)==1):\n",
    "                oWord = columns[0].strip()\n",
    "            else:\n",
    "                rWord = columns[0].strip()\n",
    "                meas = np.float(columns[1].strip())\n",
    "                if oWord in rWords:\n",
    "                    rWords[oWord] += [{rWord:meas}]\n",
    "#                        rWords1[oWord][rWord] = meas\n",
    "                else:\n",
    "                    rWords[oWord] = [{rWord:meas}]\n",
    "                    #rWords1[oWord] = {rWord:meas}\n",
    "print(\"size of rWords =\", len(rWords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if(len(methodGraphsFileName)>1):\n",
    "    print(methodGraphsFileName[1])\n",
    "    \n",
    "    if method != \"dir\":\n",
    "        print(\"reading graphs...\")\n",
    "        with open(methodGraphsFileName[1], 'r') as graphFile:\n",
    "            oWord = \"\"\n",
    "            for i, row in enumerate(graphFile):\n",
    "                columns = row.split('\\t')\n",
    "                if(len(columns)==1):\n",
    "                    oWord = columns[0].strip()\n",
    "                else:\n",
    "                    rWord = columns[0].strip()\n",
    "                    meas = np.float(columns[1].strip())\n",
    "                    if oWord in rWords1:\n",
    "#                        rWords1[oWord] += [{rWord:meas}]\n",
    "                        rWords1[oWord][rWord] = meas\n",
    "                    else:\n",
    "#                        rWords1[oWord] = [{rWord:meas}]\n",
    "                        rWords1[oWord] = {rWord:meas}\n",
    "    print(\"size of rWords1 =\", len(rWords1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#rWords1 = dict()\n",
    "#import operator\n",
    "#print(rWords1[\"consum\"])\n",
    "#print(sorted(rWords1[\"consum\"], key=operator.itemgetter(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-->  {'pawn': 1.0}\n",
      "-->  {'pawn': 1.0}\n",
      "-->  {'rook': 1.0}\n",
      "-->  {'rook': 1.0}\n",
      "on reason person book ticket\n",
      "-->  {'go on vacat': 1.0}\n",
      "encount with friend\n",
      "-->  {'plai basketbal': 1.0}\n",
      "bean-stalk\n",
      "-->  {'bean': 1.0}\n",
      "antitrad wind\n",
      "-->  {'antitrad': 1.0}\n",
      "-->  {'prevail wind': 1.58496250072}\n",
      "canada goos\n",
      "-->  {'canada': 1.0}\n",
      "-->  {'larg north american bird that honk': 1.58496250072}\n",
      "spiderl\n",
      "-->  {'-ling': 1.0}\n",
      "vinalon\n",
      "-->  {'vinyl': 1.0}\n",
      "utnapishtim\n",
      "-->  {'semit deiti': 1.58496250072}\n",
      "spideri\n",
      "-->  {'spider': 1.0}\n",
      "calvin-benson cycl\n",
      "-->  {'calvin cycl': 1.0}\n",
      "salt flat\n",
      "-->  {'flat': 1.58496250072}\n",
      "steller sea-lion\n",
      "-->  {'eumetopia jubatu': 1.0}\n",
      "fuck your mom in ass\n",
      "-->  {'regard as taboo': 1.0}\n",
      "nunneri\n",
      "-->  {'brothel': 1.0}\n",
      "-->  {'convent': 1.58496250072}\n",
      "-->  {'nun': 1.0}\n",
      "ecolog servic\n",
      "-->  {'servic': 1.0}\n",
      "reel in\n",
      "-->  {'reel': 1.0}\n",
      "w:polish corridor\n",
      "-->  {'corridor': 1.0}\n",
      "cardiospermum\n",
      "-->  {'dicot genu': 1.58496250072}\n",
      "-->  {'sapindacea': 1.58496250072}\n",
      "modelessli\n",
      "-->  {'model': 1.0}\n",
      "houyhnhnm\n",
      "-->  {'fiction charact': 1.58496250072}\n",
      "-->  {'imaginari place': 1.58496250072}\n",
      "seven-year itch\n",
      "-->  {'seven': 1.0}\n"
     ]
    }
   ],
   "source": [
    "for j, (ow, rws) in  enumerate(rWords.iteritems()):\n",
    "    print (ow)\n",
    "    for i, rw in enumerate(rws):\n",
    "        print (\"--> \", rw)\n",
    "        if i>10:\n",
    "            break\n",
    "    if j>20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cmd = ' '.join([\"dumpindex\", colIndexDir, \"s\", \"|\", \"awk\", \"\\'NR==2{print $2}\\'\"])\n",
    "c_ = subprocess.Popen(cmd , shell=True, stdout=subprocess.PIPE).stdout.read()\n",
    "#print(c_)\n",
    "N = int(c_)\n",
    "\n",
    "def mi_(N_w, N_v, N_wv):\n",
    "    #N_w = count_1(w )\n",
    "    #N_v = count_1(v )\n",
    "    #N_wv = count_2(w, v)\n",
    "    pw1 = N_w / float(N)\n",
    "    pw0 = 1 - pw1\n",
    "    pv1 = N_v / float(N)\n",
    "    pv0 = 1 - pv1\n",
    "    \n",
    "    pw1v1 = N_wv / float(N)\n",
    "    pw1v0 = (N_w - N_wv) / float(N)\n",
    "    pw0v1 = (N_v - N_wv) / float(N)\n",
    "    pw0v0 = 1 - pw0v1 - pw1v0 - pw1v1\n",
    "    \n",
    "    #print(\"w, v =\", w, v)\n",
    "    #print(\"N_w, N_v, N_wv, N =\", N_w, N_v, N_wv, N)\n",
    "    #print(\"pw0 = %f, pw1 = %f, pv0 = %f, pv1 = %f\"%(pw0, pw1, pv0, pv1))\n",
    "    #print(\"pw0v0 = %f, pw0v1 = %f, pw1v0 = %f, pw1v1 = %f\"%(pw0v0, pw0v1, pw1v0, pw1v1))\n",
    "    \n",
    "    if N_w == 0 or N_v == 0 or N_wv == 0:\n",
    "        return 0\n",
    "    if pv0 == 0 or pw0 == 0 or pv1 == 0 or pw1 == 0:\n",
    "        return 0\n",
    "    if pv1 > 0.1 or pw1 > 0.1:\n",
    "        return 0\n",
    "\n",
    "    mi = pw1v1*np.log(pw1v1/(pw1*pv1)) + pw1v0*np.log(pw1v0/(pw1*pv0)) + pw0v1*np.log(pw0v1/(pw0*pv1)) + pw0v0*np.log(pw0v0/(pw0*pv0))\n",
    "    return mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def countExpr(count_history, origWords, rWords):\n",
    "    expressions = set()\n",
    "    for ow in origWords:\n",
    "        rWords_ow = rWords.get(ow, [])\n",
    "        if ow.translate(None, string.punctuation).strip() == \"\":\n",
    "            continue\n",
    "        #print (ow)\n",
    "        expr_ow = \"#uw(#4( \" + ow.translate(None, string.punctuation) + \" ))\"\n",
    "        if(expr_ow not in count_history):\n",
    "            expressions.add(expr_ow)\n",
    "        for rw_wv in rWords_ow:\n",
    "            (rw_w, rw_v) = rw_wv.items()[0]\n",
    "            #print(rw_w)\n",
    "            if rw_w.translate(None, string.punctuation).strip() == \"\":\n",
    "                continue\n",
    "            expr_rw = \"#uw(#4( \" + rw_w.translate(None, string.punctuation) + \" ))\"\n",
    "            if(expr_rw not in count_history):\n",
    "                expressions.add(expr_rw)\n",
    "            expr_ow_rw = \"#uw(#4( \" + ow.translate(None, string.punctuation) + \" ) #4( \" + rw_w.translate(None, string.punctuation) + \" ))\"\n",
    "            if(expr_ow_rw not in count_history):\n",
    "                expressions.add(expr_ow_rw)\n",
    "    statement = \"\"\n",
    "    for expr in expressions:\n",
    "        statement += expr + \"\\n\"\n",
    "    with open(os.path.join(projectDir,\"occuranceCount\",\"statement.txt\"), 'w') as f:\n",
    "        f.write(statement)\n",
    "    cmd = ' '.join([os.path.join(projectDir,\"occuranceCount\",\"occuranceCount\"), colIndexDir, 'x', os.path.join(projectDir,\"occuranceCount\",\"statement.txt\")])\n",
    "    #print(\"cmd =\", cmd)\n",
    "    cAll = subprocess.Popen(cmd , shell=True, stdout=subprocess.PIPE).stdout.read().split(\"\\n\")\n",
    "    countExpr_ = dict()\n",
    "    for line in cAll:\n",
    "        line = line.split(':')\n",
    "        line = [l.strip() for l in line]\n",
    "        #print(\"line =\", line)\n",
    "        if len(line) == 2:\n",
    "            countExpr_[line[0]] = np.float(line[1])\n",
    "    count_history = dict(count_history.items() + countExpr_.items()) \n",
    "    #print(countExpr_)\n",
    "    return count_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def countExpr_get_1(count_history, w):\n",
    "    if w.translate(None, string.punctuation).strip() == \"\":\n",
    "        return 0;\n",
    "    #print (w)\n",
    "    return count_history[\"#uw(#4( \" + w.translate(None, string.punctuation) + \" ))\"]\n",
    "def countExpr_get_2(count_history, w, v):\n",
    "    if w.translate(None, string.punctuation).strip() == \"\" or v.translate(None, string.punctuation).strip() == \"\":\n",
    "        return 0;\n",
    "    return count_history[\"#uw(#4( \" + w.translate(None, string.punctuation) + \" ) #4( \" + v.translate(None, string.punctuation) + \" ))\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# keys of rWords are important\n",
    "# values of rWords1 are important\n",
    "regex = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "def getRelWords(count_history, rWords, origWords, expansionCount):\n",
    "    #print(\"origWords =\", origWords)\n",
    "    text_string = \"\"\n",
    "    \n",
    "    count_history = countExpr(count_history, origWords, rWords)\n",
    "        \n",
    "    relWords = dict()\n",
    "    expressions = set()\n",
    "    for ow in origWords:\n",
    "        #relWords += rWords.get(ow, [])\n",
    "        rWords_ow = rWords.get(ow, [])\n",
    "        expressions.add(\"#4( \" + ow.translate(None, string.punctuation) + \" )\")\n",
    "        #N_w = count_1( ow )\n",
    "        if ow.strip() == \"\":\n",
    "            continue\n",
    "        if simMeasure == \"mi\":\n",
    "            #print(\"ow =\", ow)\n",
    "            N_w = countExpr_get_1(count_history, ow)\n",
    "        for rw_wv in rWords_ow:\n",
    "            (rw_w, rw_v) = rw_wv.items()[0]\n",
    "            if rw_w.strip() == \"\":\n",
    "                continue           \n",
    "            if simMeasure == \"mi\":\n",
    "                #print(\"ow = %s, rw_w =%s\"%(ow, rw_w))\n",
    "                N_v = countExpr_get_1(count_history, rw_w)\n",
    "                N_wv = countExpr_get_2(count_history, ow, rw_w)\n",
    "                rw_v_ = mi_(N_w, N_v, N_wv)\n",
    "                #print(\"N_w, N_v, N_wv, rw_v_ =\", N_w, N_v, N_wv, rw_v_)\n",
    "            elif simMeasure == \"cnet\":\n",
    "                rw_v_ = rw_v\n",
    "            relWords[rw_w] = relWords.get(rw_w, 0) + rw_v_\n",
    "    relWords_sorted = sorted(relWords.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    #print (\"relWords_sorted =\", relWords_sorted)\n",
    "    #counter = 0\n",
    "    relWords_sel = []\n",
    "    for counter, (rw_w, rw_v) in enumerate(relWords_sorted):\n",
    "        if (counter >= expansionCount):\n",
    "            break\n",
    "        if  all(c in string.printable for c in rw_w):\n",
    "            if rw_w not in origWords:\n",
    "                rw_w = regex.sub(' ', rw_w)\n",
    "                text_string += rw_w + \" \"\n",
    "                relWords_sel += [rw_w]\n",
    "        #counter += 1\n",
    "    #print(\"counter =\", counter)\n",
    "    return(count_history, text_string, relWords_sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "regex = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "def genQueries(count_history, intCoeff0, intCoeff1, intCoeff2, expansionCount1, expansionCount2, dirCoeff, N1):\n",
    "    #    #print(\"intCoeff =\", intCoeff)\n",
    "    with open(cfgInFileName, 'r') as inFile:\n",
    "        reader = inFile.read()\n",
    "        soup = BeautifulSoup(reader, 'lxml')\n",
    "        soupNew = BeautifulSoup(\"\", 'lxml')\n",
    "        parameters_tag = soupNew.new_tag(\"parameters\")\n",
    "        index_tag = soupNew.new_tag(\"index\")\n",
    "        index_tag.string = colIndexDir\n",
    "        parameters_tag.append(index_tag)\n",
    "        if collection in {\"aquaint\", \"gov\"}:\n",
    "            tags = soup.find_all(['doc'])\n",
    "        elif collection in {\"robust\", \"trec7n8\"}:\n",
    "            tags = soup.find_all(['top'])\n",
    "            #print(tags)\n",
    "\n",
    "        for tag in tags:\n",
    "            #print(\"tag =\", tag)\n",
    "            #print('docno =', tag.find('docno').string)\n",
    "            #print('text =', tag.find('text').string.strip())\n",
    "            doc_tag = soupNew.new_tag(\"query\")\n",
    "\n",
    "            docno_tag = soupNew.new_tag(\"number\")\n",
    "            if collection in {\"aquaint\", \"gov\"}:\n",
    "                docno_tag.string = (tag.find('docno').string).strip()\n",
    "            elif collection in {\"robust\", \"trec7n8\"}:\n",
    "                result = re.search('<num> Number: (.*)\\n', str(tag))                \n",
    "                docno_tag.string = result.group(1).strip()\n",
    "            doc_tag.append(docno_tag)\n",
    "\n",
    "            text_tag = soupNew.new_tag(\"text\")\n",
    "            text_tag.string = \"#weight(\\n\" \n",
    "\n",
    "            if collection in {\"aquaint\", \"gov\"}:\n",
    "                origWords = splitStemText(tag.find('text').string.strip())\n",
    "            elif collection in {\"robust\", \"trec7n8\"}:\n",
    "                result = re.search('<title>(.*)\\n', str(tag))                \n",
    "                origWords = splitStemText(result.group(1).strip())\n",
    "            #print(\"origWords =\", origWords)\n",
    "                    \n",
    "            text_tag.string += str(intCoeff0) + \" #combine(\" \n",
    "            for ow in set(origWords):\n",
    "                ow = regex.sub(' ', ow)\n",
    "                text_tag.string += ow + \" \"\n",
    "            text_tag.string += \")\\n\"\n",
    "\n",
    "            \n",
    "            count_history, text_string, relWords_sel1 = getRelWords(count_history, rWords, origWords, expansionCount1)\n",
    "            #print(\"text_string =\", text_string)\n",
    "            if len(text_string)>3:\n",
    "                text_tag.string += str(intCoeff1) + \" #combine(\" \n",
    "                #print(\"text_string =\", text_string)\n",
    "                text_tag.string += text_string.encode('utf-8')\n",
    "                text_tag.string += \")\\n\"\n",
    "\n",
    "            origWords_new = relWords_sel1[0:N1]#[i[0] for i in relWords_sel]\n",
    "            count_history, text_string, relWords_sel2 = getRelWords(count_history, rWords, origWords_new, expansionCount2)\n",
    "            #print(\"text_string =\", text_string)\n",
    "            if len(text_string)>3:\n",
    "                text_tag.string += str(intCoeff2) + \" #combine(\" \n",
    "                #print(\"text_string =\", text_string)\n",
    "                text_tag.string += text_string.encode('utf-8')\n",
    "                text_tag.string += \")\\n\"\n",
    "            \n",
    "            #print(\"origWords =\", origWords)\n",
    "            #print(\"relWords_sel1 =\", relWords_sel1)\n",
    "            #print(\"relWords_sel2 =\", relWords_sel2)\n",
    "            \n",
    "            \n",
    "            text_tag.string += \") \"\n",
    "\n",
    "            doc_tag.append(text_tag)\n",
    "\n",
    "            parameters_tag.append(doc_tag)\n",
    "            #print(doc_tag)\n",
    "\n",
    "        rule_tag = soupNew.new_tag(\"rule\")\n",
    "        rule_tag.string = \"method:dir,mu:\" + str(dirCoeff)\n",
    "        #rule_tag.string = \"method:two\"\n",
    "        parameters_tag.append(rule_tag)\n",
    "\n",
    "        #intCoeff_tag = soupNew.new_tag(\"intCoeff\")\n",
    "        #intCoeff_tag.string = \"0.8\"\n",
    "        #parameters_tag.append(intCoeff_tag)\n",
    "\n",
    "        threads_tag = soupNew.new_tag(\"threads\")\n",
    "        threads_tag.string = \"32\"\n",
    "        parameters_tag.append(threads_tag)\n",
    "\n",
    "        count_tag = soupNew.new_tag(\"count\")\n",
    "        count_tag.string = \"1000\"\n",
    "        parameters_tag.append(count_tag)\n",
    "\n",
    "        trecFormat_tag = soupNew.new_tag(\"trecFormat\")\n",
    "        trecFormat_tag.string = \"true\"\n",
    "        parameters_tag.append(trecFormat_tag)\n",
    "\n",
    "        soupNew.append(parameters_tag)\n",
    "        #print(soupNew.prettify())\n",
    "    #print(\"outFileName =\", outFileName)\n",
    "    with open( cfgOutFileName, 'w') as outFile:\n",
    "        soupNewStr = str(soupNew)\n",
    "        soupNewStr = soupNewStr.replace(\"</text>\", \"\\n</text>\\n\").replace(\"query>\", \"query>\\n\").replace(\"<text>\", \"\\n<text>\\n\").replace(\"</index>\", \"</index>\\n\").replace(\"\\n<index>\", \"<index>\")\n",
    "        outFile.write(soupNewStr)\n",
    "    return count_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def precisionCompute(count_history, intCoeffs0, intCoeffs1, intCoeffs2, expansionCounts1, expansionCounts2, dirCoeffs, N1s):\n",
    "    mapPrecs = dict()\n",
    "    for N1 in N1s:\n",
    "        for intCoeff0 in intCoeffs0:\n",
    "            for intCoeff1 in intCoeffs1:\n",
    "                for intCoeff2 in intCoeffs2:\n",
    "                    for expansionCount1 in expansionCounts1:\n",
    "                        for expansionCount2 in expansionCounts2:\n",
    "                            for dirCoeff in dirCoeffs:\n",
    "                                count_history = genQueries(count_history, intCoeff0, intCoeff1, intCoeff2, expansionCount1, expansionCount2, dirCoeff, N1)\n",
    "                                subprocess.Popen(\"IndriRunQuery \" + cfgOutFileName + \" > \" + runsFileName, shell=True, stdout=subprocess.PIPE).stdout.read()\n",
    "                                cmd = \"trec_eval -q \" + colQrelsFileName + \" \" + runsFileName + \" > \" + evalsFileName\n",
    "                                subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE).stdout.read()\n",
    "                                cmd = \"cat \" + evalsFileName + \" | grep map | grep all | grep -v gm | awk '{print $3}' \"\n",
    "                                #print (\"cmd = \", cmd)\n",
    "                                mapPrec = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE).stdout.read()\n",
    "                                print(\"intCoeff0, intCoeff1, intCoeff2, expansionCount1, expansionCount2, dirCoeff, map precision, N1 =\", intCoeff0, intCoeff1, intCoeff2, expansionCount1, expansionCount2, dirCoeff, N1, mapPrec)\n",
    "                                #mapPrecs[intCoeff] = mapPrec\n",
    "    return count_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fj9124/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:32: RuntimeWarning: divide by zero encountered in log\n",
      "/home/fj9124/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:32: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/fj9124/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:32: RuntimeWarning: invalid value encountered in log\n"
     ]
    }
   ],
   "source": [
    "intCoeffs0 = [ 0.7 ]\n",
    "intCoeffs1 = [ 0.3 ]\n",
    "#intCoeffs2 = [ 0.18 ]\n",
    "intCoeffs2 = [ 0.1 ]\n",
    "#intCoeffs1 = np.arange(0, 0.5, 0.05)\n",
    "expansionCounts1 = [ 135 ]\n",
    "#expansionCounts2 = [ 145 ]\n",
    "expansionCounts2 = [ 0 ]\n",
    "expansionCounts2 = range(15, 220, 5)\n",
    "dirCoeffs = [ 1600 ]\n",
    "#dirCoeffs = range(200, 4000, 200)\n",
    "N1s = [3]\n",
    "#N1s = range(1, 30, 1)\n",
    "#mapPrecs = \n",
    "count_history = precisionCompute(count_history, intCoeffs0, intCoeffs1, intCoeffs2, expansionCounts1, expansionCounts2, dirCoeffs, N1s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of count_history = 81446\n"
     ]
    }
   ],
   "source": [
    "print(\"length of count_history =\", len(count_history))\n",
    "with open(countsResultsFile, 'w') as f:\n",
    "    for k, v in count_history.iteritems():\n",
    "        f.write(k + \"\\t\" + str(v) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
